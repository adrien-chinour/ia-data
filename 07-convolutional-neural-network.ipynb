{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional-neural-network.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YUJ1PXyChg7N",
        "ICynhh9nimvb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrien-chinour/ia-data/blob/master/07-convolutional-neural-network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f-4Eyv9g9-H",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouh3dvFdhLGF",
        "colab_type": "code",
        "outputId": "306e1c28-b0d3-48fc-a1b2-832ca8acec97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# import librairies\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.optimizers import RMSprop\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUJ1PXyChg7N",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 1 : Un premier réseau de neurones\n",
        "\n",
        "Dans cet exercice, nous allons définir un réseau avec une couche cachée contenant 1 neurone et\n",
        "une couche de sortie avec deux neurones. Le but est toujours de faire une classification binaire et\n",
        "arriver à faire la différence entre le chiffre 5 et les autres chiffres.\n",
        "1. Modifier le fichier pour implémenter ce réseau de neurones. Quelles fonctions d’activation utiliseriezvous pour la couche cachée ? Pour la couche de sortie ?\n",
        "2. Entrainer le réseau avec juste 10 epchos, le tester et mesurer sa précision. Peut-on améliorer\n",
        "encore la précision sans changer l’architecture du réseau ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMk0UXr8xTlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load (first download if necessary) the MNIST dataset\n",
        "# (the dataset is stored in your home direcoty in ~/.keras/datasets/mnist.npz\n",
        "#  and will take  ~11MB)\n",
        "# data is already split in train and test datasets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# x_train : 60000 images of size 28x28, i.e., x_train.shape = (60000, 28, 28)\n",
        "# y_train : 60000 labels (from 0 to 9)\n",
        "# x_test  : 10000 images of size 28x28, i.e., x_test.shape = (10000, 28, 28)\n",
        "# x_test  : 10000 labels\n",
        "# all datasets are of type uint8\n",
        "\n",
        "\n",
        "#To input our values in our network Dense layer, we need to flatten the datasets, i.e.,\n",
        "# pass from (60000, 28, 28) to (60000, 784)\n",
        "#flatten images\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "x_train = x_train.reshape(x_train.shape[0], num_pixels)\n",
        "x_test = x_test.reshape(x_test.shape[0], num_pixels)\n",
        "\n",
        "#Convert to float\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "#Normalize inputs from [0; 255] to [0; 1]\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "\n",
        "#We want to have a binary classification: digit 0 is classified 1 and \n",
        "#all the other digits are classified 0\n",
        "\n",
        "y_new = np.zeros(y_train.shape)\n",
        "y_new[np.where(y_train==5.0)[0]] = 1\n",
        "y_train = y_new\n",
        "\n",
        "y_new = np.zeros(y_test.shape)\n",
        "y_new[np.where(y_test==5.0)[0]] = 1\n",
        "y_test = y_new\n",
        "\n",
        "\n",
        "num_classes = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jVLWXXfxdVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Création du réseau de neurone à deux couches (1-2)\n",
        "def deep_neural_network_1():\n",
        "  nn = Sequential()\n",
        "  nn.add(Dense(1, input_dim=num_pixels, activation='relu', kernel_initializer='normal'))\n",
        "  nn.add(Dense(2, activation='softmax', kernel_initializer='normal'))\n",
        "  nn.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  return nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAPsrNPb17kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tri des résultats (y) en deux catgéories 5 et !5\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVq0SE0Z0Eae",
        "colab_type": "code",
        "outputId": "138bd1ec-a10a-48ef-d5c3-5be0a825d186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "# On entraine notre modèle\n",
        "my_network = deep_neural_network_1()\n",
        "my_network.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 1)                 785       \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 2)                 4         \n",
            "=================================================================\n",
            "Total params: 789\n",
            "Trainable params: 789\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.3384 - acc: 0.9072 - val_loss: 0.2347 - val_acc: 0.9108\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.2119 - acc: 0.9097 - val_loss: 0.1858 - val_acc: 0.9108\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.1795 - acc: 0.9097 - val_loss: 0.1638 - val_acc: 0.9108\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1609 - acc: 0.9097 - val_loss: 0.1490 - val_acc: 0.9108\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.1481 - acc: 0.9126 - val_loss: 0.1384 - val_acc: 0.9581\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1387 - acc: 0.9543 - val_loss: 0.1299 - val_acc: 0.9602\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.1315 - acc: 0.9579 - val_loss: 0.1237 - val_acc: 0.9633\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1259 - acc: 0.9600 - val_loss: 0.1190 - val_acc: 0.9656\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 15us/step - loss: 0.1214 - acc: 0.9620 - val_loss: 0.1145 - val_acc: 0.9663\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1176 - acc: 0.9632 - val_loss: 0.1111 - val_acc: 0.9683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc4587fba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR409Rbp1OCx",
        "colab_type": "code",
        "outputId": "ab66ed4f-1ebc-42af-83a7-52ff7a9142f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Score obtenu par notre modèle\n",
        "score = my_network.evaluate(x_test, y_test)\n",
        "print(\"Accuracy : %.2f%%\" %(score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 21us/step\n",
            "Accuracy : 96.83%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICynhh9nimvb",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 2 : Un réseau pour reconnaitre tous les chiffres\n",
        "\n",
        "À présent, nous allons adapter le réseau précédent pour reconnaire tous les 10 chiffres.\n",
        "1. Expliquer, avec une figure, l’architecture du nouveau réseau.\n",
        "2. Redéfinir, dans le programme, la nouvelle architecture.\n",
        "3. Entrainer et tester le nouveau réseau. Refaire les mêmes experimentations que dans l’exercice 1. Changer d’algorithme d’optimisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD0mHB0cjJfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Récupération de notre jeu de données\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "x_train = x_train.reshape(x_train.shape[0], num_pixels)\n",
        "x_test = x_test.reshape(x_test.shape[0], num_pixels)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS-XS68sjmOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Création du réseau de neurone à deux couches (1-10)\n",
        "def deep_neural_network_2():\n",
        "  nn = Sequential()\n",
        "  nn.add(Dense(1, input_dim=num_pixels, activation='relu', kernel_initializer='normal'))\n",
        "  nn.add(Dense(10, activation='softmax', kernel_initializer='normal'))\n",
        "  nn.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  return nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sD1hrBgjxDf",
        "colab_type": "code",
        "outputId": "f874c00f-d26b-4542-a3a1-cb8a4c4b32f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "# On entraine notre modèle\n",
        "my_network = deep_neural_network_2()\n",
        "my_network.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 2.2936 - acc: 0.1053 - val_loss: 2.2680 - val_acc: 0.1117\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 2.1843 - acc: 0.1465 - val_loss: 2.0918 - val_acc: 0.2176\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 2.0355 - acc: 0.2079 - val_loss: 1.9861 - val_acc: 0.2114\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 1.9608 - acc: 0.2203 - val_loss: 1.9316 - val_acc: 0.2200\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 1.9171 - acc: 0.2311 - val_loss: 1.8974 - val_acc: 0.2286\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 1.8877 - acc: 0.2396 - val_loss: 1.8734 - val_acc: 0.2408\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 1.8662 - acc: 0.2486 - val_loss: 1.8564 - val_acc: 0.2455\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 1.8497 - acc: 0.2533 - val_loss: 1.8427 - val_acc: 0.2499\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 1.8366 - acc: 0.2602 - val_loss: 1.8313 - val_acc: 0.2598\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 1.8258 - acc: 0.2657 - val_loss: 1.8222 - val_acc: 0.2663\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f226ae87898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBi5idZFj29l",
        "colab_type": "code",
        "outputId": "b12663a3-cdb6-4f8c-d382-7b7ad095ca19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Score obtenu par notre modèle\n",
        "score = my_network.evaluate(x_test, y_test)\n",
        "print(\"Accuracy : %.2f%%\" %(score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 26us/step\n",
            "Accuracy : 26.63%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cWApeA9gs0",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 3 : Un réseau CNN pour reconnaitre tous les chiffres\n",
        "Même exercice mais en utilisant une architecture en CNN.\n",
        "1. Définir un réseau de neurones à convolution avec :\n",
        "  - une couche de convolution\n",
        "  - une couche de maxpooling\n",
        "  - un réseau \"fully connected\" à plusieurs couches\n",
        "2. Entrainer le modèle et le tester.\n",
        "3. Choisir les bons hyper-paramètres pour atteindre une précision d’u moins 99%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdn2PZMckm2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Récupération du jeu de données\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "y_train = keras.utils.to_categorical(y_train,10)\n",
        "y_test = keras.utils.to_categorical(y_test,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvHjCHTZ_FLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Création de notre CNN\n",
        "def cnn():\n",
        "  nn = Sequential()\n",
        "  nn.add(Conv2D(32, kernel_size=(3,3), input_shape=(28,28,1), activation='relu'))\n",
        "  nn.add(MaxPool2D(pool_size=(2,2)))\n",
        "  nn.add(Flatten())\n",
        "  nn.add(Dense(10, activation='softmax', kernel_initializer='normal'))\n",
        "  nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40BTKy5Okxu1",
        "colab_type": "code",
        "outputId": "2ed614c1-8f2b-4553-88b8-a2a8b538cd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Entrainement de notre réseau\n",
        "my_network = cnn()\n",
        "my_network.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 26s 442us/step - loss: 0.2825 - acc: 0.9198 - val_loss: 0.1208 - val_acc: 0.9642\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.1034 - acc: 0.9704 - val_loss: 0.0758 - val_acc: 0.9757\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 26s 437us/step - loss: 0.0739 - acc: 0.9789 - val_loss: 0.0656 - val_acc: 0.9790\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 26s 436us/step - loss: 0.0601 - acc: 0.9822 - val_loss: 0.0639 - val_acc: 0.9781\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0510 - acc: 0.9847 - val_loss: 0.0618 - val_acc: 0.9786\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0455 - acc: 0.9865 - val_loss: 0.0544 - val_acc: 0.9805\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0400 - acc: 0.9883 - val_loss: 0.0537 - val_acc: 0.9818\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 27s 457us/step - loss: 0.0353 - acc: 0.9894 - val_loss: 0.0569 - val_acc: 0.9820\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.0321 - acc: 0.9904 - val_loss: 0.0541 - val_acc: 0.9831\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 30s 492us/step - loss: 0.0286 - acc: 0.9912 - val_loss: 0.0562 - val_acc: 0.9829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f226449aef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ck3U7_SlfO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "761e54bc-10a4-4581-da01-af93e08125ef"
      },
      "source": [
        "# Score obtenu par notre modèle\n",
        "score = my_network.evaluate(x_test, y_test)\n",
        "print(\"Accuracy : %.2f%%\" %(score[1]*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 161us/step\n",
            "Accuracy : 98.29%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
